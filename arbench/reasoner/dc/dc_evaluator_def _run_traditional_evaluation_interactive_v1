def _run_traditional_evaluation_interactive(
    method: str,
    dataset: List[Dict],
    logs: List[Dict],
    output_path: str,
    policy_client: InteractivePolicyClient,
    response_model: str,
    response_temperature: float,
    response_top_p: float,
    max_turn: int,
) -> None:
    """使用交互式策略运行传统评估方法 (修改版：增加full_completions日志)"""

    for i in tqdm(range(len(logs), len(dataset))):
        # 准备案例信息
        init_info = convert_initial_info_to_string(dataset[i]["initial_information"])
        label = dataset[i]["label"]

        total_input_token, total_output_token = 0, 0
        choice_str = ", ".join([
            f"{index}. {item['name']}"
            for index, item in zip(ANSWER_CHOICES, dataset[i]["initial_information"]["suspect"])
        ])

        # 系统提示
        system_content = METHOD_DICT[method].format(background=init_info, turn=max_turn)

        # 初始化嫌疑人的响应代理
        response_agents = {
            item["name"]: [{
                "role": "system",
                "content": respond_template.format(
                    name=item["name"], task=item["task"], story=item["story"]
                ),
            }]
            for item in dataset[i]["suspects"]
        }
        
        suspect_name_str = ", ".join([
            item["name"] for item in dataset[i]["initial_information"]["suspect"]
        ])

        # 存储完整对话记录
        propose_agent = [{
            "role": "system",
            "content": system_content,
        }]
        
        # --- 修改开始: 初始化日志列表 ---
        all_interactions = []
        all_completions = []  # <-- 1. 新增这个列表
        # --- 修改结束 ---

        # 问答循环
        for turn in range(max_turn):
            # 选择嫌疑人（使用交互）
            select_prompt = select_suspect_template.format(
                turn=turn + 1, suspect_names=suspect_name_str
            )
            
            propose_agent.append({
                "role": "user",
                "content": select_prompt,
            })
            
            # 获取之前的对话记录 (用于给响应模型提供上下文)
            record_str = ""
            for j, msg in enumerate(propose_agent):
                if msg["role"] == "assistant" and j > 0:
                    record_str += f"{msg['content']}\n"
            
            # 交互式选择嫌疑人
            selected_suspect, suspect_completion, suspect_interactions, input_tok, output_tok = policy_client.generate_with_interaction(
                system_prompt=system_content,
                user_prompt=select_prompt,
                response_model=response_model,
                response_api_key=RESPONSE_API_KEY,
                response_base_url=RESPONSE_BASE_URL,
                response_temperature=response_temperature,
                response_top_p=response_top_p,
                case_context={
                    'case_info': init_info,
                    'suspects': suspect_name_str,
                    'turn': turn + 1,
                    'record': record_str
                }
            )
            
            total_input_token += input_tok
            total_output_token += output_tok
            all_interactions.extend(suspect_interactions)
            
            # --- 修改开始: 记录完整的completion ---
            all_completions.append({
                "step": f"turn_{turn + 1}_select_suspect",
                "completion": suspect_completion
            })
            # --- 修改结束 ---
            
            selected_suspect = remove_punctuation_at_ends(selected_suspect)
            
            # 验证嫌疑人
            if selected_suspect not in response_agents.keys():
                print(f"Invalid suspect: {selected_suspect}, retrying...")
                propose_agent.append({"role": "assistant", "content": selected_suspect}) # 记录错误答案
                propose_agent.append({"role": "user", "content": refine_select_suspect_prompt})
                continue
            
            # (保持不变: 记录干净答案，以维持逻辑上下文)
            propose_agent.append({"role": "assistant", "content": selected_suspect})
            
            # 生成问题（使用交互）
            question_prompt = question_propose_prompt.format(turn=turn + 1)
            propose_agent.append({
                "role": "user",
                "content": question_prompt,
            })
            
            question, question_completion, question_interactions, input_tok, output_tok = policy_client.generate_with_interaction(
                system_prompt=system_content,
                user_prompt=question_prompt,
                response_model=response_model,
                response_api_key=RESPONSE_API_KEY,
                response_base_url=RESPONSE_BASE_URL,
                response_temperature=response_temperature,
                response_top_p=response_top_p,
                case_context={
                    'case_info': init_info,
                    'suspect': selected_suspect,
                    'turn': turn + 1,
                    'record': record_str  # 传递之前的干净历史
                }
            )
            
            total_input_token += input_tok
            total_output_token += output_tok
            all_interactions.extend(question_interactions)
            
            # --- 修改开始: 记录完整的completion ---
            all_completions.append({
                "step": f"turn_{turn + 1}_generate_question",
                "completion": question_completion
            })
            # --- 修改结束 ---
            
            # (保持不变: 记录干净问题，用于和模拟器交互)
            propose_agent.append({"role": "assistant", "content": question})

            # 获取嫌疑人回复（使用原始inference）
            response_agents[selected_suspect].append({"role": "user", "content": question})
            response = inference(
                response_agents[selected_suspect], 
                model=response_model, 
                temperature=response_temperature, 
                top_p=response_top_p, 
                api_key=RESPONSE_API_KEY, 
                base_url=RESPONSE_BASE_URL
            )
            suspect_response = response.choices[0].message.content
            total_input_token += response.usage.prompt_tokens
            total_output_token += response.usage.completion_tokens

            response_agents[selected_suspect].append({"role": "assistant", "content": suspect_response})
            # (保持不变: 记录干净的用户回复)
            propose_agent.append({"role": "user", "content": suspect_response})

        # 获取最终预测（使用交互）
        final_prompt = select_murderer_template.format(choice=choice_str)
        propose_agent.append({
            "role": "user",
            "content": final_prompt,
        })
        
        raw_pred, pred_completion, pred_interactions, input_tok, output_tok = policy_client.generate_with_interaction(
            system_prompt=system_content,
            user_prompt=final_prompt,
            response_model=response_model,
            response_api_key=RESPONSE_API_KEY,
            response_base_url=RESPONSE_BASE_URL,
            response_temperature=response_temperature,
            response_top_p=response_top_p,
            case_context={
                'case_info': init_info,
                'choices': choice_str,
                'record': record_str # 传递最后一次的历史记录
            }
        )
        

        total_input_token += input_tok
        total_output_token += output_tok
        all_interactions.extend(pred_interactions)
        
        # --- 修改开始: 记录完整的completion ---
        all_completions.append({
            "step": "final_prediction",
            "completion": pred_completion
        })
        # --- 修改结束 ---
        
        # (保持不变: 记录最终裁减的答案)
        propose_agent.append({"role": "assistant", "content": raw_pred})

        pred = CHOICE_TO_INDEX.get(extract_answer_choice(raw_pred), "")
        if pred == "":
            pred = CHOICE_TO_INDEX.get(extract_answer_choice(raw_pred.strip()), "") # 再次尝试

        # --- 修改开始: 在最终日志中添加新键 ---
        logs.append({
            "idx": i,
            "record": propose_agent,         # 干净的高层逻辑日志
            "interactions": all_interactions, # 内部的 <asking>/<response> 日志
            "full_completions": all_completions, # <--- 3. 你想要的带<think>的完整日志
            "respond_conversation": [
                {"name": key, "conversation": value}
                for key, value in response_agents.items()
            ],
            "pred": pred,
            "label": label,
            "round": max_turn,
            "input_token_sum": total_input_token,
            "output_token_sum": total_output_token,
            "correctness": pred == label,
        })
        # --- 修改结束 ---
        
        # 保存结果
        with open(output_path, "w", encoding="utf-8") as file:
            json.dump(logs, file, indent=4, ensure_ascii=False) # 添加 ensure_ascii=False 以防中文乱码
        
        print(f"Case {i}: Pred={pred}, Label={label}, Correct={pred==label}")


#think放在content中

def _run_traditional_evaluation_interactive(
    method: str,
    dataset: List[Dict],
    logs: List[Dict],
    output_path: str,
    policy_client: InteractivePolicyClient,
    response_model: str,
    response_temperature: float,
    response_top_p: float,
    max_turn: int,
) -> None:
    """使用交互式策略运行传统评估方法 (修改版：增加full_completions日志)"""

    for i in tqdm(range(len(logs), len(dataset))):
        # 准备案例信息
        init_info = convert_initial_info_to_string(dataset[i]["initial_information"])
        label = dataset[i]["label"]

        total_input_token, total_output_token = 0, 0
        choice_str = ", ".join([
            f"{index}. {item['name']}"
            for index, item in zip(ANSWER_CHOICES, dataset[i]["initial_information"]["suspect"])
        ])

        # 系统提示
        system_content = METHOD_DICT[method].format(background=init_info, turn=max_turn)

        # 初始化嫌疑人的响应代理
        response_agents = {
            item["name"]: [{
                "role": "system",
                "content": respond_template.format(
                    name=item["name"], task=item["task"], story=item["story"]
                ),
            }]
            for item in dataset[i]["suspects"]
        }
        
        suspect_name_str = ", ".join([
            item["name"] for item in dataset[i]["initial_information"]["suspect"]
        ])

        # 存储完整对话记录
        propose_agent = [{
            "role": "system",
            "content": system_content,
        }]
        
        # --- 修改开始: 初始化日志列表 ---
        all_interactions = []
        all_completions = []
        # --- 修改结束 ---

        # 问答循环
        for turn in range(max_turn):
            # 选择嫌疑人（使用交互）
            select_prompt = select_suspect_template.format(
                turn=turn + 1, suspect_names=suspect_name_str
            )
            
            propose_agent.append({
                "role": "user",
                "content": select_prompt,
            })
            
            # 获取之前的对话记录 (用于给响应模型提供上下文)
            record_str = ""
            for j, msg in enumerate(propose_agent):
                if msg["role"] == "assistant" and j > 0:
                    # **MODIFICATION**: Use the full completion for context if available
                    # This gives the model its own thought process back.
                    record_str += f"{msg['content']}\n"
            
            # 交互式选择嫌疑人
            selected_suspect, suspect_completion, suspect_interactions, input_tok, output_tok = policy_client.generate_with_interaction(
                system_prompt=system_content,
                user_prompt=select_prompt,
                response_model=response_model,
                response_api_key=RESPONSE_API_KEY,
                response_base_url=RESPONSE_BASE_URL,
                response_temperature=response_temperature,
                response_top_p=response_top_p,
                case_context={
                    'case_info': init_info,
                    'suspects': suspect_name_str,
                    'turn': turn + 1,
                    'record': record_str
                }
            )
            
            total_input_token += input_tok
            total_output_token += output_tok
            all_interactions.extend(suspect_interactions)
            
            all_completions.append({
                "step": f"turn_{turn + 1}_select_suspect",
                "completion": suspect_completion
            })
            
            # Use the clean extracted name for logic, but the full completion for logging
            selected_suspect_clean = remove_punctuation_at_ends(selected_suspect)
            
            # 验证嫌疑人
            if selected_suspect_clean not in response_agents.keys():
                print(f"Invalid suspect: {selected_suspect_clean}, retrying...")
                # Log the full, incorrect completion
                propose_agent.append({"role": "assistant", "content": suspect_completion}) 
                propose_agent.append({"role": "user", "content": refine_select_suspect_prompt})
                continue
            
            # --- ✨ KEY CHANGE 1 ---
            # Log the full completion instead of just the clean answer
            propose_agent.append({"role": "assistant", "content": suspect_completion})
            
            # 生成问题（使用交互）
            question_prompt = question_propose_prompt.format(turn=turn + 1)
            propose_agent.append({
                "role": "user",
                "content": question_prompt,
            })
            
            question, question_completion, question_interactions, input_tok, output_tok = policy_client.generate_with_interaction(
                system_prompt=system_content,
                user_prompt=question_prompt,
                response_model=response_model,
                response_api_key=RESPONSE_API_KEY,
                response_base_url=RESPONSE_BASE_URL,
                response_temperature=response_temperature,
                response_top_p=response_top_p,
                case_context={
                    'case_info': init_info,
                    'suspect': selected_suspect_clean,
                    'turn': turn + 1,
                    'record': record_str
                }
            )
            
            total_input_token += input_tok
            total_output_token += output_tok
            all_interactions.extend(question_interactions)
            
            all_completions.append({
                "step": f"turn_{turn + 1}_generate_question",
                "completion": question_completion
            })
            
            # --- ✨ KEY CHANGE 2 ---
            # Log the full completion for the question
            propose_agent.append({"role": "assistant", "content": question_completion})

            # 获取嫌疑人回复（使用原始inference）
            response_agents[selected_suspect_clean].append({"role": "user", "content": question})
            response = inference(
                response_agents[selected_suspect_clean], 
                model=response_model, 
                temperature=response_temperature, 
                top_p=response_top_p, 
                api_key=RESPONSE_API_KEY, 
                base_url=RESPONSE_BASE_URL
            )
            suspect_response = response.choices[0].message.content
            total_input_token += response.usage.prompt_tokens
            total_output_token += response.usage.completion_tokens

            response_agents[selected_suspect_clean].append({"role": "assistant", "content": suspect_response})
            propose_agent.append({"role": "user", "content": suspect_response})

        # 获取最终预测（使用交互）
        final_prompt = select_murderer_template.format(choice=choice_str)
        propose_agent.append({
            "role": "user",
            "content": final_prompt,
        })
        
        raw_pred, pred_completion, pred_interactions, input_tok, output_tok = policy_client.generate_with_interaction(
            system_prompt=system_content,
            user_prompt=final_prompt,
            response_model=response_model,
            response_api_key=RESPONSE_API_KEY,
            response_base_url=RESPONSE_BASE_URL,
            response_temperature=response_temperature,
            response_top_p=response_top_p,
            case_context={
                'case_info': init_info,
                'choices': choice_str,
                'record': record_str
            }
        )
        
        total_input_token += input_tok
        total_output_token += output_tok
        all_interactions.extend(pred_interactions)
        
        all_completions.append({
            "step": "final_prediction",
            "completion": pred_completion
        })
        
        # --- ✨ KEY CHANGE 3 ---
        # Log the final full completion
        propose_agent.append({"role": "assistant", "content": pred_completion})

        pred = CHOICE_TO_INDEX.get(extract_answer_choice(raw_pred), "")
        if pred == "":
            pred = CHOICE_TO_INDEX.get(extract_answer_choice(raw_pred.strip()), "")

        logs.append({
            "idx": i,
            "record": propose_agent,
            "interactions": all_interactions,
            "full_completions": all_completions,
            "respond_conversation": [
                {"name": key, "conversation": value}
                for key, value in response_agents.items()
            ],
            "pred": pred,
            "label": label,
            "round": max_turn,
            "input_token_sum": total_input_token,
            "output_token_sum": total_output_token,
            "correctness": pred == label,
        })
        
        # 保存结果
        with open(output_path, "w", encoding="utf-8") as file:
            json.dump(logs, file, indent=4, ensure_ascii=False)
        
        print(f"Case {i}: Pred={pred}, Label={label}, Correct={pred==label}")
